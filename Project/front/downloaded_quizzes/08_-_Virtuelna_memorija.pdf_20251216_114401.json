{
  "chapters": [
    {
      "chapter_number": 1,
      "content_preview": "--- Page 1 ---\nOPERATIVNI SISTEMI\nVirtuelna memorijaSlajdovi sukreirani naosnovu knjige \u201cOperativni sistemi , principi unutra \u0161nje organizacije i diza...",
      "questions": [
        {
          "question_data": {
            "correct_answer": "A) William Stallings",
            "explanation": "Page 1 explicitly states the slides are based on the book 'Operativni sistemi' by William Stallings (7th edition, CET Belgrade, 2013). Other options are notable computer scientists but unrelated to this source.",
            "options": [
              "A) William Stallings",
              "B) Andrew Tanenbaum",
              "C) Linus Torvalds",
              "D) Brian Kernighan"
            ],
            "question": "Who is the author of the book on which the operating systems slides are based?"
          },
          "solo_level": "unistructural"
        },
        {
          "question_data": {
            "correct_answer": "A) Logical addresses dynamically translated, processes swapped in/out, non-contiguous allocation",
            "explanation": "Page 3 explicitly lists: 1) Dynamic logical-to-physical translation, 2) Process swapping with variable memory locations, and 3) Non-contiguous process allocation",
            "options": [
              "A) Logical addresses dynamically translated, processes swapped in/out, non-contiguous allocation",
              "B) Fixed-size partitions, logical address translation, processes always contiguous",
              "C) Static address binding, processes loaded once permanently, contiguous allocation required",
              "D) Physical addresses used directly by processes, no swapping, fixed memory locations"
            ],
            "question": "Which of the following are characteristics of memory management as described?"
          },
          "solo_level": "multistructural"
        },
        {
          "question_data": {
            "correct_answer": "A) They collectively allow processes to exceed physical memory limits by dynamically mapping and moving memory sections",
            "explanation": "Logical address translation enables flexible memory placement, swapping allows process mobility, non-contiguous allocation reduces memory waste, and disk storage extends capacity. Together, these create the illusion of abundant memory while managing physical limitations.",
            "options": [
              "A) They collectively allow processes to exceed physical memory limits by dynamically mapping and moving memory sections",
              "B) They primarily focus on speeding up CPU operations through direct physical memory access",
              "C) They enforce strict contiguous memory allocation to simplify hardware requirements",
              "D) They eliminate the need for main memory by relying entirely on disk storage"
            ],
            "question": "How do logical address translation, process swapping, non-contiguous allocation, and disk storage work together in virtual memory systems?"
          },
          "solo_level": "relational"
        },
        {
          "question_data": {
            "correct_answer": "A) On-demand file streaming from remote servers",
            "explanation": "On-demand streaming dynamically translates file requests to physical storage locations (local/cloud), abstracting storage limits like virtual memory translates logical addresses to physical RAM/disk. Both manage resource scarcity through dynamic mapping.",
            "options": [
              "A) On-demand file streaming from remote servers",
              "B) End-to-end encryption of stored files",
              "C) Automatic file compression to save space",
              "D) Multi-user access control permissions"
            ],
            "question": "In cloud storage services that allow seamless access to files exceeding local device capacity, which feature mirrors virtual memory's dynamic address translation principle?"
          },
          "solo_level": "extended_abstract"
        }
      ],
      "title": "Page 1-8 - OPERATIVNI SISTEMI"
    },
    {
      "chapter_number": 2,
      "content_preview": "--- Page 9 ---\nIzvr\u0161avanje procesa\n\uf0a8Rezidentni skup\n\uf0a4delovi procesa koji su u glavnoj memoriji u \nodre\u0111enom trenutku\n\uf0a4Postoji indikacija za svaku stra...",
      "questions": [
        {
          "question_data": {
            "correct_answer": "A) Gre\u0161ka stranice",
            "explanation": "Na stranici 12 sadr\u017eaja eksplicitno stoji da se gre\u0161ka pri referenciranju stranice koja nije u memoriji naziva 'gre\u0161ka stranice' (page fault). Ovo je izolovani koncept iz teksta bez potrebe za povezivanjem s drugim elementima.",
            "options": [
              "A) Gre\u0161ka stranice",
              "B) Rezidentni skup",
              "C) Indikacija stranice",
              "D) Hardverska detekcija"
            ],
            "question": "Kako se naziva gre\u0161ka koja nastaje kada proces referencira stranicu koja nije u glavnoj memoriji?"
          },
          "solo_level": "unistructural"
        },
        {
          "question_data": {
            "correct_answer": "A) Resident set tracks loaded pages; Page faults occur for missing pages; Hardware detects page faults",
            "explanation": "Page 9 defines resident set as loaded pages with presence indicators. Page 12 states page faults occur when accessing missing pages, detected by hardware. Other options include unsupported claims about virtual memory (B), reboots (C), or disk pages (D).",
            "options": [
              "A) Resident set tracks loaded pages; Page faults occur for missing pages; Hardware detects page faults",
              "B) Resident set is in virtual memory; Page faults trigger OS alerts; All pages are always loaded",
              "C) Resident set changes hourly; Page faults require CPU reboot; Software monitors page presence",
              "D) Resident set includes disk pages; Page faults improve performance; Memory ignores page indicators"
            ],
            "question": "Based on pages 9-17, which list contains ONLY correct statements about process execution?"
          },
          "solo_level": "multistructural"
        },
        {
          "question_data": {
            "correct_answer": "A) Hardware intervenes to load the missing page into memory",
            "explanation": "Page faults occur when a referenced page isn't in the resident set (memory). This triggers hardware intervention to load the required page, showing how memory tracking, execution flow, and fault handling interconnect to maintain process continuity.",
            "options": [
              "A) Hardware intervenes to load the missing page into memory",
              "B) The process continues execution unimpeded",
              "C) The resident set is automatically expanded without intervention",
              "D) The referenced page is permanently removed from the process"
            ],
            "question": "What is the direct consequence of a page fault (gre\u0161ka stranice) when a process references a page not in its resident set (rezidentni skup)?"
          },
          "solo_level": "relational"
        },
        {
          "question_data": {
            "correct_answer": "A) Page fault handling",
            "explanation": "The scenario mirrors page fault handling: the main shelf acts as the resident set (active memory), storage as secondary memory, and the retrieval process resolves the 'fault' (unavailable resource) by loading the required item, similar to fetching a missing page.",
            "options": [
              "A) Page fault handling",
              "B) Process scheduling prioritization",
              "C) Memory fragmentation management",
              "D) File system indexing"
            ],
            "question": "A library uses a main shelf for popular books (limited space) and storage for others. When a user requests a book not on the main shelf, a librarian retrieves it from storage. Which computing concept does this BEST mirror?"
          },
          "solo_level": "extended_abstract"
        }
      ],
      "title": "Page 9-17 - Izvr\u0161avanje procesa"
    },
    {
      "chapter_number": 3,
      "content_preview": "--- Page 18 ---\nEfikasnost virtuelne memorije\n\uf0a8Ako je \ud835\udc5d=0.001\n\uf0a4Jedno od hiljadu referenciranja izaziva gre\u0161ku \nstranice\n\uf0a8Tada je \ud835\udc61=8.2\ud835\udf07\ud835\udc60\n\uf0a8To je uspore...",
      "questions": [
        {
          "question_data": {
            "correct_answer": "A) Less than one in 400,000 references",
            "explanation": "The text explicitly states that for good performance, page faults must occur less than once per 400,000 references (\ud835\udc5d<0.0000025). This is a direct factual requirement from the calculations shown.",
            "options": [
              "A) Less than one in 400,000 references",
              "B) One in 1,000 references",
              "C) One in 40,000 references",
              "D) One in 7,999,800 references"
            ],
            "question": "According to the text , what maximum page fault rate ensures good virtual memory performance?"
          },
          "solo_level": "unistructural"
        }
      ],
      "title": "Page 18-24 - Efikasnost virtuelne memorije"
    },
    {
      "chapter_number": 4,
      "content_preview": "--- Page 25 ---\nPodr\u0161ka za virtuelnu memoriju\n\uf0a8Hardverska\n\uf0a4Hardver procesora mora da podr\u017ei adresiranje \nstranica/segmenata\n\uf0a8Softverska\n\uf0a4OS mora da po...",
      "questions": [
        {
          "question_data": {
            "correct_answer": "A) Da li je stranica prisutna u glavnoj memoriji",
            "explanation": "Na stranici 27 eksplicitno stoji da indikator P u tabeli stranica ozna\u010dava prisutnost stranice u glavnoj memoriji ('P \u2013 da li je stranica prisutna u memoriji'). Ostale opcije nisu spomenute u datom sadr\u017eaju.",
            "options": [
              "A) Da li je stranica prisutna u glavnoj memoriji",
              "B) Da li je stranica za\u0161ti\u0107ena od pisanja",
              "C) Prioritet stranice prilikom zamene",
              "D) Veli\u010dinu stranice u bajtovima"
            ],
            "question": "\u0160ta indikator P (prisutnost) u stavci tabele stranica ozna\u010dava?"
          },
          "solo_level": "unistructural"
        },
        {
          "question_data": {
            "correct_answer": "A) Hardware addressing, OS moving pages, page tables per process, presence bit",
            "explanation": "The correct answer lists independent elements directly stated in the content: Hardware addressing (pg25), OS moving pages (pg25), page tables per process (pg26), and presence bit (P) in page table entries (pg27). Other options include unrelated concepts like cache memory or TLB registers.",
            "options": [
              "A) Hardware addressing, OS moving pages, page tables per process, presence bit",
              "B) Cache memory, interrupt handling, page tables per process, access rights",
              "C) Hardware addressing, disk scheduling, shared page tables, modification bit",
              "D) OS moving pages, TLB registers, process priority, presence bit"
            ],
            "question": "According to pages 25-31, which elements are explicitly mentioned as part of virtual memory support?"
          },
          "solo_level": "multistructural"
        },
        {
          "question_data": {
            "correct_answer": "A) To reduce the number of memory accesses required for address translation",
            "explanation": "The TLB caches recent page table entries to avoid redundant memory accesses. Without it, each data access would require two memory reads: one for the page table and another for the actual data, as described in the summary.",
            "options": [
              "A) To reduce the number of memory accesses required for address translation",
              "B) To increase the physical memory capacity available to processes",
              "C) To eliminate the need for a presence bit (P) in page table entries",
              "D) To allow larger page sizes for more efficient disk transfers"
            ],
            "question": "What is the primary reason virtual memory systems use a Translation Lookaside Buffer (TLB) alongside the page table?"
          },
          "solo_level": "relational"
        },
        {
          "question_data": {
            "correct_answer": "A) Maintain a list of recent catalog lookups",
            "explanation": "This mirrors the TLB cache in virtual memory systems, which stores recent page table entries to avoid full memory accesses for frequent translations, directly applying the core principle of caching address mappings.",
            "options": [
              "A) Maintain a list of recent catalog lookups",
              "B) Store all books on shelves permanently",
              "C) Remove the catalog entirely",
              "D) Randomly discard books from shelves"
            ],
            "question": "A library uses a catalog to track books on shelves (main memory) vs. storage (disk). How can they optimize frequent book access?"
          },
          "solo_level": "extended_abstract"
        }
      ],
      "title": "Page 25-31 - Podr\u0161ka za virtuelnu memoriju"
    },
    {
      "chapter_number": 5,
      "content_preview": "--- Page 32 ---\nReferenciranje uz kori\u0161\u0107enje TLB\n\uf0a8Proverava se da li je stranica u glavnoj \nmemoriji\n\uf0a4Ako nije, generi\u0161e se gre\u0161ka stranice ( page fau...",
      "questions": [
        {
          "question_data": {
            "correct_answer": "B) The page number and the complete page table entry",
            "explanation": "Page 34 explicitly states: 'stavka TLB mora da sadr\u017ei broj stranice i kompletnu stavku' (TLB entry must contain the page number and the complete entry), directly requiring both elements in associative mapping.",
            "options": [
              "A) Only the page number",
              "B) The page number and the complete page table entry",
              "C) The physical address and offset",
              "D) The frame number and access rights"
            ],
            "question": "According to TLB associative mapping , what must each TLB entry contain?"
          },
          "solo_level": "unistructural"
        },
        {
          "question_data": {
            "correct_answer": "A) Checks page presence in memory; OS loads pages on fault; TLB entries include page numbers",
            "explanation": "A is correct: Page 32 confirms TLB checks memory presence, OS manages page faults, and TLB entries include page numbers . B/C/D are incorrect: TLB uses associative mapping (not direct), holds partial entries (not all), requires updates beyond faults, and isn't indexed by offset.",
            "options": [
              "A) Checks page presence in memory; OS loads pages on fault; TLB entries include page numbers",
              "B) Uses direct mapping; contains all page table entries; updates only on faults",
              "C) CPU handles page faults; TLB doesn't require updates; entries indexed by offset",
              "D) Associative mapping enables direct indexing; TLB stores full page table; CPU updates TLB"
            ],
            "question": "Which statements are correct about TLB referencing from pages 32-34?"
          },
          "solo_level": "multistructural"
        },
        {
          "question_data": {
            "correct_answer": "A) Querying authoritative DNS servers if the domain isn't cached",
            "explanation": "Just as TLB triggers OS page fault handling for missing pages, a DNS resolver queries external servers when a domain isn't cached. Both involve external resolution mechanisms for missing entries.",
            "options": [
              "A) Querying authoritative DNS servers if the domain isn't cached",
              "B) Updating TLB entries after a cache hit",
              "C) Using associative mapping for cache storage",
              "D) Incrementing a counter for frequently accessed domains"
            ],
            "question": "A DNS resolver uses a cache to store domain-to-IP mappings. Which step mirrors how TLB handles page faults?"
          },
          "solo_level": "extended_abstract"
        }
      ],
      "title": "Page 32-38 - Referenciranje uz kori\u0161\u0107enje TLB"
    },
    {
      "chapter_number": 6,
      "content_preview": "--- Page 39 ---\nTabela stranica\n\uf0a8Tabela stranica mo\u017ee da bude prevelika da bi \nse \u010duvala u glavnoj memoriji\n\uf0a8Jedna varijanta re\u0161enja je sme\u0161tanje tabe...",
      "questions": [
        {
          "question_data": {
            "correct_answer": "A) The page table is too large for main memory",
            "explanation": "Page 39 explicitly states: 'Tabela stranica mo\u017ee da bude prevelika da bi se \u010duvala u glavnoj memoriji' (The page table can be too large to be stored in main memory), with virtual memory storage offered as a solution.",
            "options": [
              "A) The page table is too large for main memory",
              "B) The need for hierarchical page tables",
              "C) Slow access to page table entries",
              "D) Memory fragmentation issues"
            ],
            "question": "According to the text, what problem does storing the page table in virtual memory solve?"
          },
          "solo_level": "unistructural"
        },
        {
          "question_data": {
            "correct_answer": "A) Size issues, Virtual memory storage, Hierarchical structure, Partial main memory requirement",
            "explanation": "Option A correctly identifies four independent facts: 1) Page tables can be too large for main memory (p39), 2) Storage in virtual memory is a solution (p39), 3) Hierarchical structure is an alternative (p40), and 4) Part must reside in main memory during execution (p39)",
            "options": [
              "A) Size issues, Virtual memory storage, Hierarchical structure, Partial main memory requirement",
              "B) Single-level design, Direct physical addressing, Complete RAM storage, No access during execution",
              "C) Fixed small size, GPU storage, Linear addressing, Automatic hardware reload",
              "D) Cache-only storage, Atomic entries, Dynamic resizing, Permanent disk storage"
            ],
            "question": "Which option lists FOUR correct aspects from pages 39-40 about page tables?"
          },
          "solo_level": "multistructural"
        },
        {
          "question_data": {
            "correct_answer": "A) It eliminates the need for linear traversal of all frames to locate page table entries",
            "explanation": "The hierarchical structure breaks the page table into smaller levels, allowing targeted lookups instead of scanning all entries linearly (as described in the summary). This avoids the inefficiency of exhaustive searches in large tables while keeping critical portions in memory (pages 39-40).",
            "options": [
              "A) It eliminates the need for linear traversal of all frames to locate page table entries",
              "B) It reduces the total memory required to store the entire page table",
              "C) It makes page table access simpler by dividing responsibilities",
              "D) It allows faster direct access to physical memory addresses"
            ],
            "question": "Why does a hierarchical page table structure improve efficiency compared to a single-level page table when dealing with large address spaces?"
          },
          "solo_level": "relational"
        },
        {
          "question_data": {
            "correct_answer": "A) Use a multi-level index where top-level directs to sub-indexes",
            "explanation": "Hierarchical page tables use multiple levels (like a top table pointing to subtables) to efficiently manage large data with minimal memory. Similarly, a multi-level library index optimizes quick access while avoiding full memory storage, transferring the core principle to a new context.",
            "options": [
              "A) Use a multi-level index where top-level directs to sub-indexes",
              "B) Store the entire index on slow secondary storage",
              "C) Require librarians to linearly search all shelves",
              "D) Randomly split the index without hierarchy"
            ],
            "question": "A library's book catalog becomes too large for a single index. Which approach mirrors hierarchical page tables to balance speed and memory?"
          },
          "solo_level": "extended_abstract"
        }
      ],
      "title": "Page 39-46 - Tabela stranica"
    },
    {
      "chapter_number": 7,
      "content_preview": "--- Page 47 ---\nZa\u0161tita memorije\n\uf0a8Da li je odre\u0111ena memorijska lokacija\n\uf0a4Samo za \u010ditanje \n\uf0a4\u010citanje i upis\n\uf0a4Samo za izvr\u0161avanje\n\uf0a8Implementira se dodatn...",
      "questions": [
        {
          "question_data": {
            "correct_answer": "B) Dodatnim bitovima u stavci tabele stranica",
            "explanation": "Na stranici 47 jasno je navedeno da se za\u0161tita implementira dodatnim bitovima u stavci tabele stranica, s po jednim bitom za svaki tip za\u0161tite (samo \u010ditanje, \u010ditanje/upis, samo izvr\u0161avanje). Ostale opcije nisu spomenute u datom sadr\u017eaju.",
            "options": [
              "A) Hardverskim prekidima",
              "B) Dodatnim bitovima u stavci tabele stranica",
              "C) Softverskim zastavicama",
              "D) Posebnim registrima procesora"
            ],
            "question": "Kako se implementira za\u0161tita memorije prema tekstu?"
          },
          "solo_level": "unistructural"
        },
        {
          "question_data": {
            "correct_answer": "A) Read-only bits, read/write bits, execute-only bits, and access prevention via virtual memory",
            "explanation": "The text explicitly lists three protection bits (read-only, read/write, execute-only) in page table entries (p47) and access prevention through virtual memory's implicit isolation (p48). Other options include unrelated concepts like encryption or cache protection.",
            "options": [
              "A) Read-only bits, read/write bits, execute-only bits, and access prevention via virtual memory",
              "B) Encryption keys, permission bits, and hardware isolation",
              "C) Page table bits, process isolation, and access prevention",
              "D) Cache protection, execute-only bits, and virtual address mapping"
            ],
            "question": "According to pages 47-48, which features are described as part of memory protection?"
          },
          "solo_level": "multistructural"
        },
        {
          "question_data": {
            "correct_answer": "A) Hardware checks protection bits during address translation to enforce both access permissions and process isolation",
            "explanation": "The protection bits in page table entries (read/write/execute permissions) are checked by the processor's hardware during virtual-to-physical address translation",
            "options": [
              "A) Hardware checks protection bits during address translation to enforce both access permissions and process isolation",
              "B) The OS verifies protection bits before access, while hardware handles only address mapping",
              "C) Protection bits solely define access types, while isolation is managed through separate OS mechanisms",
              "D) Hardware ignores protection bits and relies entirely on virtual-to-physical mapping for isolation"
            ],
            "question": "How do protection bits in page table entries and hardware-based virtual address translation work together to enforce memory protection?"
          },
          "solo_level": "relational"
        },
        {
          "question_data": {
            "correct_answer": "A) Implement row-level permissions and transaction isolation levels",
            "explanation": "Memory protection uses permission bits (like read/write) similar to database row-level permissions, while virtual memory isolation mirrors transaction isolation levels that prevent interference between concurrent operations - transferring core access control and isolation principles to a new cont...",
            "options": [
              "A) Implement row-level permissions and transaction isolation levels",
              "B) Encrypt all database tables and require decryption keys for access",
              "C) Use checksums to verify data integrity before any transaction",
              "D) Partition the database into separate physical storage devices"
            ],
            "question": "How could memory protection principles (read/write/execute permissions and process isolation) be applied to secure database transactions?"
          },
          "solo_level": "extended_abstract"
        }
      ],
      "title": "Page 47-54 - Za\u0161tita memorije"
    },
    {
      "chapter_number": 8,
      "content_preview": "--- Page 55 ---\nPolitika sme\u0161tanja\n\uf0a8Odre\u0111uje gde u glavnoj memoriji proces treba \nda bude sme\u0161ten\n\uf0a8Ako sistem koristi strani\u010denje (\u0161to je slu\u010daj u \nve...",
      "questions": [
        {
          "question_data": {
            "correct_answer": "A) Gde u glavnoj memoriji proces treba da bude sme\u0161ten",
            "explanation": "Politika sme\u0161tanja se eksplicitno defini\u0161e kao odrednica za pozicioniranje procesa u glavnoj memoriji (stranica 55). Ostale opcije odnose se na politiku zamene ili tehni\u010dke detalje strani\u010denja.",
            "options": [
              "A) Gde u glavnoj memoriji proces treba da bude sme\u0161ten",
              "B) Koja stranica treba da bude zamenjena kada je memorija puna",
              "C) Kako hardver prevodi virtuelne adrese",
              "D) Broj dostupnih okvira u glavnoj memoriji"
            ],
            "question": "\u0160ta Politika sme\u0161tanja odre\u0111uje prema sadr\u017eaju?"
          },
          "solo_level": "unistructural"
        },
        {
          "question_data": {
            "correct_answer": "A) Placement policy is irrelevant in paging systems; Replacement policy aims to minimize page faults",
            "explanation": "Page 55 states placement policy is irrelevant in paging systems, while pages 56-57 explain replacement policy's goal is to minimize page faults. These are two independent facts without requiring connection.",
            "options": [
              "A) Placement policy is irrelevant in paging systems; Replacement policy aims to minimize page faults",
              "B) Placement policy handles page replacement; Replacement policy uses hardware address translation",
              "C) Both policies work together to optimize CPU usage; Placement policy selects frames for new processes",
              "D) Replacement policy determines initial page location; Placement policy uses a FIFO algorithm"
            ],
            "question": "Based on pages 55-61, which option lists TWO CORRECT separate facts about memory management policies?"
          },
          "solo_level": "multistructural"
        },
        {
          "question_data": {
            "correct_answer": "A) Modified pages require extra I/O to write back, while new pages are likely needed soon",
            "explanation": "The replacement policy minimizes page faults by avoiding costly write-backs for modified pages (extra I/O) and retaining newly fetched pages likely to be used immediately. This connects page state (modified/recent) to performance impact, showing how policy logic optimizes the whole system.",
            "options": [
              "A) Modified pages require extra I/O to write back, while new pages are likely needed soon",
              "B) Modified pages are larger, and new pages fragment memory",
              "C) Hardware translation prevents replacing these pages",
              "D) Placement policy prioritizes these pages over others"
            ],
            "question": "How does the replacement policy's goal to minimize page faults relate to its avoidance of replacing modified or newly fetched pages?"
          },
          "solo_level": "relational"
        },
        {
          "question_data": {
            "correct_answer": "A) Replace least frequently used items",
            "explanation": "Like page replacement policies aiming to minimize page faults, replacing the least frequently used items in a warehouse reduces future restocking needs by prioritizing retention of high-demand stock\u2014directly transferring the core principle of optimizing access patterns to a new domain.",
            "options": [
              "A) Replace least frequently used items",
              "B) Replace oldest items first",
              "C) Replace most recently arrived items",
              "D) Replace newest items first"
            ],
            "question": "In a warehouse with limited space, which replacement policy minimizes future restocking trips when new stock arrives?"
          },
          "solo_level": "extended_abstract"
        }
      ],
      "title": "Page 55-61 - Politika sme\u0161tanja"
    },
    {
      "chapter_number": 9,
      "content_preview": "--- Page 62 ---\nOptimalna politika\n\uf0a8Bira se ona stranica za koju je vreme do \nslede\u0107e reference najdu\u017ee\n\n--- Page 63 ---\nOptimalna politika\n\uf0a8Ova polit...",
      "questions": [
        {
          "question_data": {
            "correct_answer": "A) The page with the longest time until its next reference",
            "explanation": "Page 62 explicitly states that the Optimal Policy selects the page that will not be referenced for the longest time in the future ('Bira se ona stranica za koju je vreme do slede\u0107e reference najdu\u017ee').",
            "options": [
              "A) The page with the longest time until its next reference",
              "B) The most recently used page",
              "C) The least recently used page",
              "D) A random page"
            ],
            "question": "According to the Optimal Policy described, which page is selected for replacement?"
          },
          "solo_level": "unistructural"
        },
        {
          "question_data": {
            "correct_answer": "A) 1, 2, and 3",
            "explanation": "Statements 1-3 are directly stated features: selection criteria (p62), non-implementability due to future knowledge (p63), and benchmarking role (p63). Statement 4 is false - the 3-frame example (p64) illustrates the policy but isn't a fixed requirement.",
            "options": [
              "A) 1, 2, and 3",
              "B) 1 and 3 only",
              "C) 2 and 4 only",
              "D) All four statements"
            ],
            "question": "Which of the following correctly describes features of the Optimal Page Replacement Policy?"
          },
          "solo_level": "multistructural"
        }
      ],
      "title": "Page 62-71 - Optimalna politika"
    },
    {
      "chapter_number": 10,
      "content_preview": "--- Page 72 ---\nPrva unutra, prva napolje -primer\n\uf0a8Vi\u0161e gre\u0161aka od LRU\n\uf0a8Za razliku od LRU ne prepoznaje stranice koje su \n\u010de\u0161\u0107e referencirane od ostal...",
      "questions": [
        {
          "question_data": {
            "correct_answer": "A) Hardver",
            "explanation": "Na stranici 73 eksplicitno stoji: 'hardver za svaku stranicu a\u017eurira bit upotrebe'. Ostale opcije nisu pomenute u kontekstu a\u017euriranja ovog bita.",
            "options": [
              "A) Hardver",
              "B) Operativni sistem",
              "C) Softver aplikacije",
              "D) Korisni\u010dki programi"
            ],
            "question": "\u0160ta a\u017eurira bit upotrebe za stranice prema LRU aproksimacijama?"
          },
          "solo_level": "unistructural"
        },
        {
          "question_data": {
            "correct_answer": "A) More errors than LRU; Doesn't recognize frequently referenced pages; Hardware updates usage bit; OS can reset usage bit",
            "explanation": "The text explicitly states: (1) the algorithm has more errors than LRU, (2) it doesn't recognize frequently referenced pages, (3) hardware updates the usage bit when pages are referenced, and (4) the OS can reset usage bits",
            "options": [
              "A) More errors than LRU; Doesn't recognize frequently referenced pages; Hardware updates usage bit; OS can reset usage bit",
              "B) Fewer errors than LRU; Uses a clock pointer; OS sets usage bit; Requires timestamp tracking",
              "C) Recognizes frequently used pages; Hardware resets usage bit; Less overhead than LRU; Uses a stack implementation",
              "D) Identical performance to LRU; Software-only implementation; Tracks least frequently used pages; Automatic bit reset"
            ],
            "question": "According to pages 72-78, which of these are features of the 'Prva unutra, prva napolje' algorithm or LRU approximations mentioned in the text?"
          },
          "solo_level": "multistructural"
        },
        {
          "question_data": {
            "correct_answer": "A) It tracks page usage, allowing OS to identify and prioritize frequently referenced pages.",
            "explanation": "The 'bit upotrebe' records page references, enabling OS to identify frequently accessed pages and approximate LRU performance, addressing the limitation of 'Prva unutra, prva napolje' in not recognizing such pages.",
            "options": [
              "A) It tracks page usage, allowing OS to identify and prioritize frequently referenced pages.",
              "B) It replaces pages randomly, avoiding reliance on reference patterns.",
              "C) It resets all page usage data periodically to ensure fairness in replacement.",
              "D) It uses hardware to fully replicate LRU without any modifications."
            ],
            "question": "How does the use of the 'bit upotrebe' in LRU approximation policies address the limitation of not recognizing frequently referenced pages in 'Prva unutra, prva napolje'?"
          },
          "solo_level": "relational"
        },
        {
          "question_data": {
            "correct_answer": "A) Use a usage bit to track data access and periodically reset it to identify less accessed data.",
            "explanation": "The concept of tracking and resetting a usage bit to determine frequently accessed data aligns with the approximation of LRU principles, adapting it to optimize storage in a cloud database system.",
            "options": [
              "A) Use a usage bit to track data access and periodically reset it to identify less accessed data.",
              "B) Continuously move frequently accessed data to faster storage without tracking usage.",
              "C) Delete rarely accessed data without tracking or resetting any usage metrics.",
              "D) Use a random selection method to decide which data to prioritize for faster storage."
            ],
            "question": "How would an approximation of LRU work in a cloud database system handling frequently accessed and rarely accessed data to optimize storage usage?"
          },
          "solo_level": "extended_abstract"
        }
      ],
      "title": "Page 72-78 - Prva unutra, prva napolje -primer"
    },
    {
      "chapter_number": 11,
      "content_preview": "--- Page 79 ---\nUpravljanje rezidentnim skupom\n\uf0a8OS za svaki proces treba da odlu\u010di koliko \nokvira da mu dodeli za sme\u0161tanje stranica\n\uf0a4\u0160to je manje mem...",
      "questions": [
        {
          "question_data": {
            "correct_answer": "A) More page faults occur",
            "explanation": "Allocating fewer frames to a process increases the likelihood of page faults since there is less space to store the necessary pages in memory.",
            "options": [
              "A) More page faults occur",
              "B) Fewer processes can be in memory",
              "C) Page faults decrease significantly",
              "D) The process runs faster"
            ],
            "question": "What happens if fewer frames are allocated to a process?"
          },
          "solo_level": "unistructural"
        },
        {
          "question_data": {
            "correct_answer": "A) Number of page faults, memory size, locality principle",
            "explanation": "The OS considers page faults, memory size, and the locality principle when deciding how many frames to allocate to a process.",
            "options": [
              "A) Number of page faults, memory size, locality principle",
              "B) Cache size, processor speed, memory access time",
              "C) Disk space, CPU usage, cache hit rate",
              "D) Network speed, thread count, page size"
            ],
            "question": "What are the considerations for assigning memory frames to a process?"
          },
          "solo_level": "multistructural"
        },
        {
          "question_data": {
            "correct_answer": "A) Increasing frames beyond a certain limit reduces page faults slightly.",
            "explanation": "The principle of locality suggests that after a certain threshold, increasing allocated memory frames has diminishing returns, as the process's locality minimizes page faults.",
            "options": [
              "A) Increasing frames beyond a certain limit reduces page faults slightly.",
              "B) Fewer frames always result in fewer page faults.",
              "C) Allocating more frames always eliminates page faults.",
              "D) Locality principle does not impact frame allocation."
            ],
            "question": "How does the principle of locality affect the relationship between the number of allocated memory frames and page faults?"
          },
          "solo_level": "relational"
        },
        {
          "question_data": {
            "correct_answer": "A) Fewer processes can run simultaneously, but page faults decrease.",
            "explanation": "Increasing memory per process reduces page faults (locality principle), but fewer processes fit in memory, lowering simultaneous execution and impacting efficiency.",
            "options": [
              "A) Fewer processes can run simultaneously, but page faults decrease.",
              "B) System efficiency increases due to fewer processes in memory.",
              "C) Page faults increase as memory allocation expands.",
              "D) More processes can run simultaneously, reducing page faults."
            ],
            "question": "If a cloud computing platform allocates virtual memory to processes based on workload, how could increasing the minimum memory per process impact system efficiency?"
          },
          "solo_level": "extended_abstract"
        }
      ],
      "title": "Page 79-85 - Upravljanje rezidentnim skupom"
    },
    {
      "chapter_number": 12,
      "content_preview": "--- Page 86 ---\nAlgoritam u\u010destalosti gre\u0161ke stranice\n\uf0a8Svakoj stranici se pridru\u017euje bit upotrebe\n\uf0a8Broja\u010d referenci koji broji koliko je proteklo \nref...",
      "questions": [
        {
          "question_data": {
            "correct_answer": "A) It is reset to 0",
            "explanation": "After a page fault, the algorithm resets the use bit of all pages in the resident set to 0, as stated in the content.",
            "options": [
              "A) It is reset to 0",
              "B) It is set to 1",
              "C) It is increased by 1",
              "D) It remains unchanged"
            ],
            "question": "What happens to the use bit of all pages in the resident set after a page fault?"
          },
          "solo_level": "unistructural"
        },
        {
          "question_data": {
            "correct_answer": "A) Usage bit, reference counter, threshold F",
            "explanation": "The algorithm includes the usage bit, reference counter, and threshold F to manage page faults and adjust the resident set size.",
            "options": [
              "A) Usage bit, reference counter, threshold F",
              "B) Cache size, memory type, disk speed",
              "C) Algorithm speed, CPU cycles, cache line",
              "D) Reference table, buffer size, processor type"
            ],
            "question": "Which elements are part of the page fault frequency algorithm?"
          },
          "solo_level": "multistructural"
        },
        {
          "question_data": {
            "correct_answer": "A) It determines whether to expand or shrink the resident set.",
            "explanation": "If the time since the last page fault is less than F, the set expands; if it's greater, the set shrinks by removing pages with a usage bit of 0.",
            "options": [
              "A) It determines whether to expand or shrink the resident set.",
              "B) It resets all reference counters to zero.",
              "C) It only expands the resident set regardless of the threshold.",
              "D) It removes all pages with a reference counter greater than F."
            ],
            "question": "How does the comparison between the reference counter and the threshold F affect the adjustment of the resident set?"
          },
          "solo_level": "relational"
        },
        {
          "question_data": {
            "correct_answer": "A) Adjust buffer size dynamically based on playback interruptions.",
            "explanation": "The algorithm's principle of adjusting the resident set based on fault frequency can be generalized to dynamically resize the buffer in response to playback interruptions, optimizing memory allocation.",
            "options": [
              "A) Adjust buffer size dynamically based on playback interruptions.",
              "B) Use fixed buffer sizes for all videos, regardless of interruptions.",
              "C) Increase buffer size only when memory usage is low.",
              "D) Disregard playback interruptions and focus on network speed."
            ],
            "question": "How could the principles of the page fault frequency algorithm be adapted to optimize memory allocation in a real-time video streaming service?"
          },
          "solo_level": "extended_abstract"
        }
      ],
      "title": "Page 86-90 - Algoritam u\u010destalosti gre\u0161ke stranice"
    },
    {
      "chapter_number": 13,
      "content_preview": "--- Page 91 ---\nPolitika \u010di\u0161\u0107enja\n\uf0a8Odlu\u010duje kada se izmenjena stranica upisuje \nnazad u sekundarnu memoriju\n\uf0a8\u010ci\u0161\u0107enje po zahtevu\n\uf0a4Stranica se upisuje ...",
      "questions": [
        {
          "question_data": {
            "correct_answer": "A) Writing the page when selected for replacement",
            "explanation": "'\u010ci\u0161\u0107enje po zahtevu' refers to writing the page back to secondary memory only when it is selected for replacement.",
            "options": [
              "A) Writing the page when selected for replacement",
              "B) Writing pages periodically in batches",
              "C) Buffering pages before replacement",
              "D) Separating pages into modified and unmodified lists"
            ],
            "question": "What does '\u010di\u0161\u0107enje po zahtevu' involve?"
          },
          "solo_level": "unistructural"
        },
        {
          "question_data": {
            "correct_answer": "A) Cleaning on demand and pre-cleaning",
            "explanation": "The text mentions cleaning on demand (writing pages when chosen for replacement) and pre-cleaning (writing pages beforehand in batches).",
            "options": [
              "A) Cleaning on demand and pre-cleaning",
              "B) Immediate cleaning and delayed cleaning",
              "C) Manual cleaning and auto-cleaning",
              "D) Scheduled cleaning and ad-hoc cleaning"
            ],
            "question": "Which cleaning policies are mentioned in the text?"
          },
          "solo_level": "multistructural"
        },
        {
          "question_data": {
            "correct_answer": "A) Pre-cleaning minimizes unnecessary resource usage by reducing disk operations.",
            "explanation": "Pre-cleaning writes pages in advance in batches, but if a page is modified again, it can waste resources. This highlights the balance needed for resource efficiency in the cleaning policy.",
            "options": [
              "A) Pre-cleaning minimizes unnecessary resource usage by reducing disk operations.",
              "B) Pre-cleaning eliminates the need for tracking modified pages entirely.",
              "C) Pre-cleaning ensures all pages are immediately written to disk upon modification.",
              "D) Pre-cleaning avoids creating separate lists for modified and unmodified pages."
            ],
            "question": "How does the use of pre-cleaning relate to resource efficiency and the overall cleaning policy?"
          },
          "solo_level": "relational"
        },
        {
          "question_data": {
            "correct_answer": "A) Implement a pre-cleaning policy with periodic batch writes.",
            "explanation": "Pre-cleaning in batches minimizes redundant writes and improves efficiency, especially in systems with frequent modifications like cloud storage.",
            "options": [
              "A) Implement a pre-cleaning policy with periodic batch writes.",
              "B) Always write changes immediately upon modification.",
              "C) Avoid pre-cleaning and rely solely on on-demand cleaning.",
              "D) Use a single list for all modified and unmodified files."
            ],
            "question": "How would you optimize memory management in a cloud storage system where multiple users frequently modify shared files?"
          },
          "solo_level": "extended_abstract"
        }
      ],
      "title": "Page 91-97 - Politika \u010di\u0161\u0107enja"
    }
  ],
  "metadata": {
    "config": {
      "distribution_mode": "auto",
      "question_mode": "auto",
      "solo_distribution": null,
      "total_questions": null,
      "use_smart_chunking": true
    },
    "distribution_mode": "auto",
    "filename": "08_-_Virtuelna_memorija.pdf",
    "generated_at": "2025-12-16T11:22:25.507439",
    "progress": {
      "chapters_completed": 13,
      "questions_generated": 46,
      "total_chapters": 13,
      "total_questions_target": 50
    },
    "question_mode": "auto",
    "total_chapters": 13,
    "total_questions": 46
  }
}